#!/usr/bin/env python3
"""
Daur MedIA - HunyuanVideo Interface
–ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å HunyuanVideo –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –±–µ–∑ —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö API
"""

import os
import sys
import torch
import argparse
import logging
from pathlib import Path
from typing import Optional, Dict, Any

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ HunyuanVideo
sys.path.insert(0, '/home/ubuntu/HunyuanVideo')

try:
    from hyvideo.utils.file_utils import save_videos_grid
    from hyvideo.config import parse_args
    from hyvideo.inference import HunyuanVideoSampler
    HUNYUAN_AVAILABLE = True
except ImportError as e:
    print(f"HunyuanVideo –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    HUNYUAN_AVAILABLE = False

class HunyuanVideoGenerator:
    """–ö–ª–∞—Å—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é HunyuanVideo"""
    
    def __init__(self, model_path: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
        
        Args:
            model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        self.model_path = model_path
        self.sampler = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.initialized = False
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
    def initialize(self) -> bool:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ HunyuanVideo
        
        Returns:
            bool: True –µ—Å–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞
        """
        if not HUNYUAN_AVAILABLE:
            self.logger.error("HunyuanVideo –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
            return False
            
        try:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è HunyuanVideo
            args = argparse.Namespace(
                video_size=(720, 1280),
                video_length=129,
                infer_steps=50,
                prompt="",
                seed=None,
                cfg_scale=1.0,
                embedded_cfg_scale=6.0,
                reproduce=True,
                batch_size=1,
                save_path="./results",
                name="test",
                model_base=self.model_path or "Tencent-Hunyuan/HunyuanVideo",
                dit_weight=None,
                vae_weight=None,
                text_encoder_weight=None,
                text_encoder_2_weight=None,
                tokenizer=None,
                tokenizer_2=None,
                flow_reverse=True,
                use_cpu_offload=False,
                save_memory=False,
                ulysses_degree=1,
                ring_degree=1,
                disable_autocast=False
            )
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–º–ø–ª–µ—Ä–∞
            self.sampler = HunyuanVideoSampler.from_pretrained(
                args.model_base, 
                args=args
            )
            
            self.initialized = True
            self.logger.info(f"HunyuanVideo –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {self.device}")
            return True
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ HunyuanVideo: {e}")
            return False
    
    def generate_video(
        self,
        prompt: str,
        video_size: tuple = (720, 1280),
        video_length: int = 129,
        infer_steps: int = 50,
        seed: Optional[int] = None,
        cfg_scale: float = 1.0,
        embedded_cfg_scale: float = 6.0,
        save_path: str = "./results",
        filename: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é
        
        Args:
            prompt: –¢–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ
            video_size: –†–∞–∑–º–µ—Ä –≤–∏–¥–µ–æ (–≤—ã—Å–æ—Ç–∞, —à–∏—Ä–∏–Ω–∞)
            video_length: –î–ª–∏–Ω–∞ –≤–∏–¥–µ–æ –≤ –∫–∞–¥—Ä–∞—Ö
            infer_steps: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
            seed: –°–∏–¥ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
            cfg_scale: –ú–∞—Å—à—Ç–∞–± CFG
            embedded_cfg_scale: –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–∞—Å—à—Ç–∞–± CFG
            save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            filename: –ò–º—è —Ñ–∞–π–ª–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        if not self.initialized:
            if not self.initialize():
                return {
                    "success": False,
                    "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å HunyuanVideo"
                }
        
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            os.makedirs(save_path, exist_ok=True)
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            if seed is None:
                seed = torch.randint(0, 2**32 - 1, (1,)).item()
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ
            self.logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤–∏–¥–µ–æ: '{prompt}'")
            self.logger.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: —Ä–∞–∑–º–µ—Ä={video_size}, –¥–ª–∏–Ω–∞={video_length}, —à–∞–≥–∏={infer_steps}")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            height, width = video_size
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é HunyuanVideo
            outputs = self.sampler.predict(
                prompt=prompt,
                height=height,
                width=width,
                video_length=video_length,
                seed=seed,
                infer_steps=infer_steps,
                guidance_scale=cfg_scale,
                embedded_guidance_scale=embedded_cfg_scale,
                batch_size=1,
                num_videos_per_prompt=1
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if filename is None:
                filename = f"video_{seed}.mp4"
            
            output_path = os.path.join(save_path, filename)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∏–¥–µ–æ
            save_videos_grid(outputs, output_path, fps=24)
            
            self.logger.info(f"–í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
            
            return {
                "success": True,
                "output_path": output_path,
                "seed": seed,
                "prompt": prompt,
                "video_size": video_size,
                "video_length": video_length,
                "infer_steps": infer_steps
            }
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
        
        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–æ–¥–µ–ª–∏
        """
        return {
            "initialized": self.initialized,
            "device": self.device,
            "cuda_available": torch.cuda.is_available(),
            "hunyuan_available": HUNYUAN_AVAILABLE,
            "model_path": self.model_path
        }

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    parser = argparse.ArgumentParser(description="Daur MedIA HunyuanVideo Generator")
    parser.add_argument("--prompt", type=str, required=True, help="–¢–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ")
    parser.add_argument("--output", type=str, default="./output", help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
    parser.add_argument("--width", type=int, default=1280, help="–®–∏—Ä–∏–Ω–∞ –≤–∏–¥–µ–æ")
    parser.add_argument("--height", type=int, default=720, help="–í—ã—Å–æ—Ç–∞ –≤–∏–¥–µ–æ")
    parser.add_argument("--length", type=int, default=129, help="–î–ª–∏–Ω–∞ –≤–∏–¥–µ–æ –≤ –∫–∞–¥—Ä–∞—Ö")
    parser.add_argument("--steps", type=int, default=50, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞")
    parser.add_argument("--seed", type=int, default=None, help="–°–∏–¥ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏")
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
    generator = HunyuanVideoGenerator()
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ
    result = generator.generate_video(
        prompt=args.prompt,
        video_size=(args.height, args.width),
        video_length=args.length,
        infer_steps=args.steps,
        seed=args.seed,
        save_path=args.output
    )
    
    if result["success"]:
        print(f"‚úÖ –í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–æ: {result['output_path']}")
        print(f"üé≤ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π —Å–∏–¥: {result['seed']}")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {result['error']}")

if __name__ == "__main__":
    main()
